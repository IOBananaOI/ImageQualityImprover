{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "api_token = {\"username\":\"iobananaoi\",\"key\":\"0cbdda23beeb18cbb57e9e88bf26bfd1\"}\n",
        "\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "vCXvsBORekQs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "7-mNAlIEV_Hm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "import zipfile\n",
        "import cv2\n",
        "import os\n",
        "import kaggle\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "lr = 1e-3\n",
        "epochs = 10\n",
        "device = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aUUGbHoGXcoo",
        "outputId": "b72aecbd-1248-447e-8a90-f85151acc060"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data processing"
      ],
      "metadata": {
        "id": "QeYfHdVmXdnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d balraj98/summer2winter-yosemite"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_4S-sU-en5I",
        "outputId": "554e691b-343f-4854-e15e-3f0090798e52"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading summer2winter-yosemite.zip to /content\n",
            " 97% 123M/126M [00:01<00:00, 102MB/s]\n",
            "100% 126M/126M [00:01<00:00, 110MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = zipfile.ZipFile(\"/content/summer2winter-yosemite.zip\")\n",
        "f.extractall(\"/content/imgs\")"
      ],
      "metadata": {
        "id": "Etulcg0DXfC6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HrLrImages(Dataset):\n",
        "    def __init__(self, src = \"/content/imgs/trainA/\", transform=None):\n",
        "        self.src = src\n",
        "        self.transform = transform\n",
        "        \n",
        "        imgs = os.listdir(src)\n",
        "        if not os.path.isdir(src+\"low_res\"):\n",
        "            os.mkdir(src+\"low_res\")\n",
        "\n",
        "        for i, img in enumerate(imgs):\n",
        "            if img[-4:] == \".jpg\":\n",
        "                new_name = str(i) + \".jpg\"\n",
        "                os.rename(src+img, src+new_name)\n",
        "                img_hr = cv2.imread(src+new_name)\n",
        "                cv2.imwrite(src+\"low_res/\"+new_name, img_hr, [int(cv2.IMWRITE_JPEG_QUALITY), 10])\n",
        "            \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(os.listdir(self.src))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        name = str(idx)+\".jpg\"\n",
        "        img_hr = cv2.imread(self.src+name)\n",
        "        img_lr = cv2.imread(self.src+\"low_res/\"+ name)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img_hr = self.transform(img_hr)\n",
        "            img_lr = self.transform(img_lr)\n",
        "\n",
        "        return img_hr, img_lr"
      ],
      "metadata": {
        "id": "KD7SXo-XX18H"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = HrLrImages(transform=ToTensor())"
      ],
      "metadata": {
        "id": "ArtGWgzIZQBz"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "CP956hLlm4Vl"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btFWEZTRsTAW",
        "outputId": "b3813403-3b78-4673-b66e-ba70b40d72c7"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 256, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model structure"
      ],
      "metadata": {
        "id": "mOpohW7CriyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AE, self).__init__()\n",
        "\n",
        "        # Encoder part\n",
        "        \n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=2, dilation=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.PReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=2, dilation=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.PReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=2, dilation=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.PReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(69696, 20096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(20096, 5024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(5024, 1256)\n",
        "        )\n",
        "\n",
        "        # Decoder part: the output should be a 256x256 image\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            torch.nn.Linear(1256, 5024),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(5024, 20096),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(20096, 256*256),\n",
        "            torch.nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "i85OIk1Zptdl"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training part"
      ],
      "metadata": {
        "id": "1d1NQwjBvPzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, optimizer, loss_fn):\n",
        "    # for epoch in range(epochs):\n",
        "    #print(f\"======== Epoch {epoch+1} ========\")\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        pred = model(X)\n",
        "        print(pred)\n",
        "        break"
      ],
      "metadata": {
        "id": "DdDaBjANvNZy"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AE()\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "TRIjsgu6uJI4"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, dataloader, optimizer, loss_fn)"
      ],
      "metadata": {
        "id": "pCGZBKZdwimx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LSyZpv3bwsp6"
      },
      "execution_count": 70,
      "outputs": []
    }
  ]
}